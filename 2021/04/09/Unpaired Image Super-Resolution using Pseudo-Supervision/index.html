<!DOCTYPE html>
<html>
<head hexo-theme='https://volantis.js.org/#2.6.6'>
  <meta charset="utf-8">
  <!-- SEO相关 -->
  
    
  
  <!-- 渲染优化 -->
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <!-- 页面元数据 -->
  
    <title>阅读论文-Unpaired Image Super-Resolution using Pseudo-Supervision - Shiyu&#39;s Blog</title>
  
    <meta name="keywords" content="super-resolution,pseudo-supervision,unpaired">
  
  
    <meta name="description" content="
出处：CVPR2020">
  

  <!-- feed -->
  
    <link rel="alternate" href="/atom.xml" title="Shiyu's Blog">
  

  <!-- import meta -->
  
    
      <meta name='theme-color' content='#FFFFFF'>
    
      <meta name='msapplication-TileColor' content='#1BC3FB'>
    
      <meta name='msapplication-config' content='https://cdn.jsdelivr.net/gh/xaoxuu/assets@master/favicon/favicons/browserconfig.xml'>
    
  

  <!-- link -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13/css/all.min.css">
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">

  

  

  

  

  <!-- import link -->
  
  
  <link rel='shortcut icon' type='image/x-icon' href='https://cdn.jsdelivr.net/gh/xaoxuu/assets@master/favicon/favicon.ico'>
  <link rel='icon' type='image/x-icon' sizes='32x32' href='https://cdn.jsdelivr.net/gh/xaoxuu/assets@master/favicon/favicons/favicon-32x32.png'>
  <link rel='apple-touch-icon' type='image/png' sizes='180x180' href='https://cdn.jsdelivr.net/gh/xaoxuu/assets@master/favicon/favicons/apple-touch-icon.png'>
  <link rel='mask-icon' color='#1BC3FB' href='https://cdn.jsdelivr.net/gh/xaoxuu/assets@master/favicon/favicons/safari-pinned-tab.svg'>
  <link rel='manifest' href='https://cdn.jsdelivr.net/gh/xaoxuu/assets@master/favicon/favicons/site.webmanifest'>
  

  
  
    
<link rel="stylesheet" href="/css/style.css">

  

  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width=num+"%";
    }
  </script>

  
  
</head>

<body>
  
  <div class="cover-wrapper">
    
      <cover class='cover post half'>
        <div class='cover-body'>
  <div class='a'>
    
    
      <p class="title">Shiyu</p>
    
    
  </div>
  <div class='b'>
    
      <div class="m_search">
        <form name="searchform" class="form u-search-form">
          <input type="text" class="input u-search-input" placeholder="" />
          <i class="icon fas fa-search fa-fw"></i>
        </form>
      </div>
    
    <div class='menu navigation'>
      <ul class='cover-list-h'>
        
      </ul>
    </div>
  </div>
</div>

      </cover>
    
    <div id="loading-bar-wrapper">
  <div id="loading-bar"></div>
</div>
<header class="l_header floatable">
  <div class='container'>
  <div class='wrapper'>
    <div class='nav-sub'>
      <p class="title"></p>
      <ul class='switcher nav-list-h'>
        <li><a class="s-comment fas fa-comments fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
          <li><a class="s-toc fas fa-list fa-fw" target="_self" href='javascript:void(0)'></a></li>
        
      </ul>
    </div>
		<div class="nav-main">
      
        
        <a class="title flat-box" target="_self" href='/'>
          
          
          
            Shiyu
          
          
        </a>
      

			<div class='menu navigation'>
				<ul class='nav-list-h'>
          
          
          
            
            
              <li>
                <a class="flat-box" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/categories/
                  
                  
                  
                    id="categories"
                  >
                  <i class='fas fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/tags/
                  
                  
                  
                    id="tags"
                  >
                  <i class='fas fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/archives/
                  
                  
                  
                    id="archives"
                  >
                  <i class='fas fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="flat-box" href=/about/
                  
                  
                  
                    id="about"
                  >
                  <i class='fas fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
          
				</ul>
			</div>

      <div class="m_search">
        <form name="searchform" class="form u-search-form">
          <i class="icon fas fa-search fa-fw"></i>
          <input type="text" class="input u-search-input" placeholder="Search..." />
        </form>
      </div>

			<ul class='switcher nav-list-h'>
				
					<li><a class="s-search fas fa-search fa-fw" target="_self" href='javascript:void(0)'></a></li>
				
				<li>
          <a class="s-menu fas fa-bars fa-fw" target="_self" href='javascript:void(0)'></a>
          <ul class="menu-phone list-v navigation white-box">
            
              
            
              <li>
                <a class="flat-box" href=/
                  
                  
                  
                    id="home"
                  >
                  <i class='fas fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/categories/
                  
                  
                  
                    id="categories"
                  >
                  <i class='fas fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/tags/
                  
                  
                  
                    id="tags"
                  >
                  <i class='fas fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/archives/
                  
                  
                  
                    id="archives"
                  >
                  <i class='fas fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="flat-box" href=/about/
                  
                  
                  
                    id="about"
                  >
                  <i class='fas fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
            
          </ul>
        </li>
			</ul>
		</div>
	</div>
  </div>
</header>

<script>setLoadingBarProgress(40);</script>

  </div>


  <div class="l_body">
    <div class='body-wrapper'>
      

<div class='l_main'>
  

  
    <article id="post" class="post white-box reveal shadow article-type-post" itemscope itemprop="blogPost">
      


  <section class='meta'>
    
      
      
      <div class="meta" id="header-meta">
        
          
  <h1 class="title">
    <a href="/2021/04/09/Unpaired%20Image%20Super-Resolution%20using%20Pseudo-Supervision/">
      阅读论文-Unpaired Image Super-Resolution using Pseudo-Supervision
    </a>
  </h1>


        
        <div class='new-meta-box'>
          
            
          
            
              
<div class='new-meta-item author'>
  <a href="" rel="nofollow">
    <img src="https://cdn.jsdelivr.net/gh/Shiyuuuu/CDN@1.0/3.jpg">
    <p>Shiyu</p>
  </a>
</div>

            
          
            
              
  
  <div class='new-meta-item category'>
    <a href='/categories/Paper-reading/super-resolution/' rel="nofollow">
      <i class="fas fa-folder-open fa-fw" aria-hidden="true"></i>
      <p>Paper reading/super-resolution</p>
    </a>
  </div>


            
          
            
              <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：Apr 9, 2021</p>
  </a>
</div>

            
          
            
              

            
          
        </div>
        
          <hr>
        
      </div>
    
  </section>


      <section class="article typo">
        <div class="article-entry" itemprop="articleBody">
          
          <p><img src="/2021/04/09/Unpaired%20Image%20Super-Resolution%20using%20Pseudo-Supervision/image-20210409155557355.png" alt></p>
<p>出处：CVPR2020</p>
<a id="more"></a>
<p><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Maeda_Unpaired_Image_Super-Resolution_Using_Pseudo-Supervision_CVPR_2020_paper.pdf" target="_blank" rel="noopener">paper</a>  <a href="https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Maeda_Unpaired_Image_Super-Resolution_CVPR_2020_supplemental.pdf" target="_blank" rel="noopener">supplemental</a>   </p>
<h2 id="motivation"><a href="#motivation" class="headerlink" title="motivation"></a>motivation</h2><ul>
<li><p>unpaired super-resolution，当aligned 的HR-LR training set is unavailable.</p>
</li>
<li><p>deviation between the generated LR distribution and the true LR distribution causes train-test discrepancy</p>
</li>
</ul>
<h2 id="contribution"><a href="#contribution" class="headerlink" title="contribution"></a>contribution</h2><p>（author: propose a new training method that overcomes the shortcomings of the existing GAN based unpaired super-resolution methods: generated LR distribution and the true LR distribution causes train-test discrepancy）</p>
<ol>
<li>bridge the gap between the well-studied existing SR methods and the real-world SR problem without paired datasets.</li>
<li>Because our correction network is trained on not only the generated LR images but also the true LR images through the bi-directional structure (因为我们的校正网络不仅通过生成的LR图像进行训练，而且还通过双向结构对真实的LR图像进行训练) : minimize the train-test discrepancy</li>
<li>any existing SR networks and pixel-wise loss function can be integrated because the SR network is separated to be able to learn in a paired manner. (SR网络可以pair对的学习)</li>
</ol>
<p>包含unpaired kernel/noise correction network和pseudo-paired SR network</p>
<p><strong>unpaired kernel/noise correction network</strong>: 去除噪声、调整输入图像的kernel，从输入的HR图像生成pseudo-clean的LR图像</p>
<p><strong>pseudo paired SR network</strong>: 学习pseudo-clean的LR image到输入的HR image的映射</p>
<p>SR网络独立于效验网络(correction network)</p>
<h2 id="related-works"><a href="#related-works" class="headerlink" title="related works"></a>related works</h2><ol>
<li><p>paired SR：</p>
<p>VDSR, EDSR, RCAN，LapSRN，DBPN</p>
</li>
<li><p>blind SR [39,12,57]</p>
<p>由任意的kernel降质得到的LR，学习由这样的LR到HR的映射，但当真实图像不是以假设的degradation降质的，（degradation估计不准），就会让真实图像SR的任务很差。</p>
<p>ZSSR， IKC， </p>
<p>关于blind SR的研究很少涉及blur kernels以外的综合降质问题（比如noise，compression artifact)。</p>
</li>
<li><p>GAN based methods [51,4,56, 32]</p>
<p>可以直接学习LR 到HR的映射，不需要degradation的假设。</p>
<p>可以大致分为两类：一类是直接从LR image出发，在生成的HR image和真实的HR image之间加discriminator. 这种方式的确定是无法用pixel wise的loss，因为real HR是未知的。</p>
</li>
</ol>
<p>另一类是，在HR到LR的过程加GAN，生成的LR image和真实的LR image之间加discriminator，使生成的LR尽可能逼近真实的LR image。然后生成的LR与原来的HR之间用pixel-wise的loss训练一个LR2HR的网络，也就是U。与cycleGAN的区别：HR端没有discriminator。缺点：生成的LR分布与真实的LR分布存在偏差，导致在training set和test set性能差别大。（当test set的图像分布在training set中完全没有）</p>
<p><img src="/2021/04/09/Unpaired%20Image%20Super-Resolution%20using%20Pseudo-Supervision/image-20210409160510814.png" alt></p>
<p>ICCV 2017: DualGAN: Unsupervised Dual Learning for Image-to-Image Translation </p>
<p>ICCV 2017: CycleGAN</p>
<p>ECCV 2018：To learn image super-resolution, use a gan to learn how to do image degradation first  </p>
<p><img src="/2021/04/09/Unpaired%20Image%20Super-Resolution%20using%20Pseudo-Supervision/image-20210409160610485.png" alt></p>
<p>ICCVW 2019：Unsupervised learning for real-world super-resolution  </p>
<p><img src="/2021/04/09/Unpaired%20Image%20Super-Resolution%20using%20Pseudo-Supervision/image-20210409160931259.png" alt></p>
<p>以上两个第一次训练HR2LR的网络，并用degraded的输出训练LR2HR的网络。</p>
<p>CVPRW 2018：Unsupervised image super-resolution using cycle-in-cycle generative adversarial networks  </p>
<p>提出cycle-in-cycle network，但他们的degradation网络是确定的，并且SR网络与bi-cycle网络合在一起。选择loss function的时候有局限性</p>
<p><img src="/2021/04/09/Unpaired%20Image%20Super-Resolution%20using%20Pseudo-Supervision/image-20210409161306839.png" alt></p>
<p>input LR $x$， GT HR $z$， $z$ bicubic下采样得到$y$ (clean LR)</p>
<p>先看里面的LR2clean LR，$x\sim x’ $  (半个cycleGAN)</p>
<p>生成得到的clean LR 进SR网络，与GT送入判别器$D_2$，通过$G_3$再回到real LR space，$x \sim x’’$</p>
<p>【pixel-wise loss不能用在HR space】</p>
<p>arxiv 2018：Unsupervised degradation learning for single image super-resolution </p>
<p><img src="/2021/04/09/Unpaired%20Image%20Super-Resolution%20using%20Pseudo-Supervision/image-20210409161600361.png" alt></p>
<p>利用了双向的结构，他们也在选择loss function的时候有局限性</p>
<p>以上4种，ECCV 2018人脸的和arxiv 2018的这篇基本基于cycleGAN的结构。</p>
<p>这篇文章和以上这些文章最主要的区别是，解决了在训练数据集和测试数据集分布不一致的问题。也就是pseudo-clean LR 和 real LR</p>
<ol>
<li><p>通过硬件和数据对齐的操作建立 real SR的数据集：</p>
<p>ICCV 2019：Toward real-world single image super-resolution: A new benchmark and a new model  </p>
<p>CVPR 2019：Camera lens super-resolution  </p>
<p>CVPR 2019：Zoom to learn, learn to zoom  </p>
</li>
</ol>
<h2 id="method"><a href="#method" class="headerlink" title="method"></a>method</h2><p>解决其他GAN-based unpaired SR的缺点：separating the entire network into an unpaired kernel/noise correction network and a pseudo-paired<br>SR network  </p>
<p>correction network：是一个cycleGAN， 完成的是unpaired的real LR和 clean LR之间的translation。clean LR由HR经过predetermined operation得到。</p>
<p>SR network：成对的学习pseudo-clean LR到HR mapping</p>
<p>在训练阶段，correction network也先由clean LR到true LR再回到clean LR生成pseudo-clean的LR 图像。SR network成对的学习pseudo-clean LR image到HR的mapping。</p>
<p>学习印射$F_{XY}:(X)LR-&gt;(Y)HR$, 定义 clean LR：$Y_\downarrow$是由$Y$经过一个指定的下采样操作得到的：$Y\rightarrow Y_\downarrow$是bicubic 下采样和gaussian blur的组合得到的。本文将$F_{XY}$拆分为两个mapping$G_{XY_\downarrow}$和$U_{Y_\downarrow Y}$的组合。</p>
<p><img src="/2021/04/09/Unpaired%20Image%20Super-Resolution%20using%20Pseudo-Supervision/image-20210409161658477.png" alt></p>
<p><strong>domain transfer in LR</strong>，其中学习mapping$G_{XY_\downarrow}$是通过上图蓝框中cycleGAN的结构</p>
<p><strong>mapping from LR to HR</strong>，只看绿线部分，由HR domain出发，先经过bicubic+Gaussian的下采样得到clean LR $Y_\downarrow$, 再把它依次过cycleGAN的两个generator得到pseudo-clean LR $\mathring{y_{\downarrow}}$ , pseudo-clean LR到HR的mapping为$U_{Y_\downarrow Y}$. 而$\mathring{y_{\downarrow}}$和y是成pair的，所以经过$U_{Y_\downarrow Y}$上采样得到的$U_{Y_\downarrow Y}(\mathring{y_{\downarrow}})$与y 之间可以用任意的pixel-wise的loss。</p>
<p><strong>HR discriminator</strong>, 希望减小训练和测试的偏差，尽管$\mathring{y_{\downarrow}}$用来训练SR网络，但是实际应用的时候，输入的LR image是$G_{XY_\downarrow}(x)$。所以pseudo clean LR和由real LR生成的clean LR的超分辨率后的差异尽可能小，所以最后还在这二者过$U_{Y_\downarrow Y}$的输出上加判别器$D_{X_\uparrow}$ </p>
<p><strong>test phase</strong>, 黑色实线部分，由real LR image先印射到 clean LR image $G_{XY_\downarrow}(x)$，（cycleGAN训练到比较理想情况的时候, clean LR 与由real LR生成的clean LR 以及pseudo clean LR都很接近）</p>
<h3 id="loss-function"><a href="#loss-function" class="headerlink" title="loss function"></a>loss function</h3><p>对于两个生成器和3个判别器，总共的loss：</p>
<script type="math/tex; mode=display">
\mathcal{L}_{trans}=\mathcal{L}_{adv}(G_{XY_\downarrow}, D_{Y_\downarrow}, X, Y_\downarrow)+\mathcal{L}_{adv}(G_{Y_\downarrow X}, D_{X}, Y_\downarrow, X)\\
+\gamma\mathcal{L}_{adv}((G_{XY_\downarrow},G_{Y_\downarrow X}),D_{X_\uparrow}, Y_\downarrow,X_\uparrow)\\
+\lambda_{cyc}\mathcal{L}_{cyc}(G_{Y_\downarrow X},G_{XY_\downarrow})+\lambda_{idt}\mathcal{L}_{idt}(G_{XY_\downarrow})+\lambda_{geo}\mathcal{L}_{geo}(G_{XY_\downarrow})</script><p>其中，$\mathcal{L}_{adv}((G_{XY_\downarrow},G_{Y_\downarrow X}),D_{X_\uparrow}, Y_\downarrow,X_\uparrow)$是HR discriminator的loss:</p>
<script type="math/tex; mode=display">
\mathcal{L}_{adv}((G_{XY_\downarrow},G_{Y_\downarrow X}),D_{X_\uparrow}, Y_\downarrow,X_\uparrow)\\
=\mathbb{E}_{x\sim P_x}[logD_{X_\uparrow}(U_{Y_\downarrow Y}\circ G_{XY_\downarrow}(x))]\\
+\mathbb{E}_{y_\downarrow \sim P_{Y_\downarrow}}[log(1-D_{X_\uparrow}(U_{Y_\downarrow Y}(\mathring{y_\downarrow})))]</script><p>cycle consistency loss 被放松到只有单向的：</p>
<script type="math/tex; mode=display">
\mathcal{L}_{cyc}=||G_{XY_\downarrow}\circ G_{Y_\downarrow X}(y_\downarrow)-y_\downarrow||_1</script><p>这使$G_{Y_\downarrow X}$可以一对多，满足不同的噪声和LR图像的分布。</p>
<p>identity loss在cycleGAN里用来保持图像的色彩，本文中也用了identity loss来避免色彩偏差:</p>
<script type="math/tex; mode=display">
\mathcal{L}_{idt}(G_{XY_\downarrow})=||G_{XY_\downarrow}(y_\downarrow)-y_\downarrow||_1</script><p><strong>geometric ensemble loss</strong> [CVPR 2019: Geometry consistent generative adversarial networks for one-sided unsupervised domain mapping] 减少可能的translation来保持场景的几何形状。本文中的geometric ensemble loss用来保证输入图像翻转、旋转不改变结果。</p>
<script type="math/tex; mode=display">
\mathcal{L}_{geo}(G_{XY_\downarrow})=||G_{XY_\downarrow}(x)-\sum_{i=1}^{8}T_i^{-1}(G_{XY_\downarrow}(T_i(x)))/8||_1</script><p>共带有8中翻转旋转模式。</p>
<p>而SR网络$U_{Y_\downarrow Y}$是与生成器、判别器无关的网络，只是用来放大图像的局部特征来作为HR端判别器的输入。用下式来更新SR网络:</p>
<script type="math/tex; mode=display">
\mathcal{L}_{rec}=||U_{Y_\downarrow Y(\mathring y_{\downarrow})}-y||_1</script><p>这里的$\mathcal{L}_{rec}$可以由任意的pixel wise的loss代替。（perceptual loss, texture loss, adversarial loss)</p>
<h3 id="network-architecture"><a href="#network-architecture" class="headerlink" title="network architecture"></a>network architecture</h3><p>最上面那路的$G_{XY_\downarrow}$和 $U_{Y_\downarrow Y}$用RCAN的网络</p>
<p>而$G_{Y_\downarrow X}$的网络结构：resBlock+fusion layers+BN+Leaky ReLU</p>
<p>判别器：patchGAN，LR的判别器的stride=1,5层卷积, HR的判别器前面几层stride=2.</p>
<h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h3 id="synthetic-distortions"><a href="#synthetic-distortions" class="headerlink" title="synthetic distortions"></a>synthetic distortions</h3><p>DIV2K realistic-wild dataset (800 训练图像)</p>
<p>simulate ： 4倍下采样、运动模糊、pixel shifting、加性噪声</p>
<p>每张图只有一种degradation，但是图像与图像之间的degradation不同，对于每张训练图像，合成4张降质图像。</p>
<p>训练：800 HR+3200 LR（unpair）</p>
<p>测试：100张validation set</p>
<p>超参：$\lambda_{cyc}=1, \lambda_{idt}=1,\gamma=0.1$, 4倍SR</p>
<p><strong>intermediate images</strong> </p>
<p><img src="/2021/04/09/Unpaired%20Image%20Super-Resolution%20using%20Pseudo-Supervision/image-20210409161744947.png" alt></p>
<p><strong>compare with blind methods</strong> </p>
<p>blind denoising: <strong>NC</strong> [The noise clinic: a blind image denoising algorithm], <strong>RL-restore</strong> [ CVPR 2018: Crafting a toolchain for image restoration by deep reinforcement learning]</p>
<p>【blind denoising还有CVPR 2019: Toward Convolutional Blind Denoising of Real Photographs (Kai Zhang)】</p>
<p>blind deblurring: <strong>SRN-Deblur</strong>[CVPR 2018: Scale-recurrent network for deep image deblurring], <strong>DeblurGAN-v2</strong> [Arxiv2019：Deblurgan-v2: Deblurring (orders-of-magnitude) faster and better]</p>
<p>SR: DBPN(non-blind), <strong>ZSSR</strong>, <strong>IKC</strong> (blind)（zssr: CVPR2018, IKC: cvpr 2019)</p>
<p>ZSSR+KernelGAN </p>
<p>这些方法是用的各自论文里提及的数据集训练，没有在这里的数据集上训练。</p>
<p><img src="/2021/04/09/Unpaired%20Image%20Super-Resolution%20using%20Pseudo-Supervision/image-20210409161830641.png" alt></p>
<p><strong>compare with NTIRE 2018 baselines</strong> 这些baseline是pair-trained （upper bounds) 这篇论文的方法PSNR比不过 baseline方法，但是SSIM与baseline方法相当. 因为PSNR高估了整体的亮度和色彩的细微差别，这些差别不会显著影响perceptual quality。</p>
<p><img src="/2021/04/09/Unpaired%20Image%20Super-Resolution%20using%20Pseudo-Supervision/image-20210409161857570.png" alt></p>
<p><strong>ablation study</strong> </p>
<p><img src="/2021/04/09/Unpaired%20Image%20Super-Resolution%20using%20Pseudo-Supervision/image-20210409161919268.png" alt></p>
<p>第2行：去除HR的判别器</p>
<p>第3行：SR network是在$y_\downarrow$上训练的，而不是$\mathring{y_\downarrow}$上，这就相当于一个real LR和Gaussian+bicubic LR之间translation的网络(cycle GAN)加一个SR网络。</p>
<p>第4行：SR network是在$G_{Y_\downarrow X}(y_\downarrow)$ 上训练的，而不是$\mathring{y_\downarrow}$上. 相当于图1 的b</p>
<p>第5行：在第4行基础上，用RCAN官方的模型做validation。</p>
<p><strong>perception-oriented training</strong> </p>
<p>在HR的$\mathcal{L}_{rec}$里加上perceptual loss, content loss (ESRGAN里面的)，relativistic adversarial loss.</p>
<p>加上这些loss 后视觉效果比L1 loss好</p>
<p><img src="/2021/04/09/Unpaired%20Image%20Super-Resolution%20using%20Pseudo-Supervision/image-20210409162036375.png" alt></p>
<h3 id="realistic-distortion-1"><a href="#realistic-distortion-1" class="headerlink" title="realistic distortion 1"></a>realistic distortion 1</h3><p>follow unsupervised 人脸SR [ECCV 2018: To learn image super-resolution, use a gan to learn how to do image degradation ﬁrst]</p>
<p>HR face images: Celeb-A, AFLW, LS3D-W, VGGFace2 (64*64)</p>
<p>LR face images: 50000张Widerface 包含多种degradation（留出3000作为测试）(16*16)</p>
<script type="math/tex; mode=display">
\mathcal{L}_{\bar{idt}}(G_{XY_\downarrow})=||G_{XY_\downarrow}(x)-x||_1</script><p>他们实验发现identity loss加在x上比加在$y_\downarrow$ 上好。</p>
<p>超参：$\lambda_{cyc}=1,\lambda_{\bar{idt}}=2,\lambda_{geo}=1,\gamma=0.1$</p>
<p>训练2倍SR：32*32=&gt;64*64</p>
<p>视觉指标FID比较：高亮的为基于GAN的unpaired的方法。</p>
<p><img src="/2021/04/09/Unpaired%20Image%20Super-Resolution%20using%20Pseudo-Supervision/image-20210409162101131.png" alt></p>
<p><strong>one-to-many degradation</strong> </p>
<p><img src="/2021/04/09/Unpaired%20Image%20Super-Resolution%20using%20Pseudo-Supervision/image-20210409162120879.png" alt></p>
<h3 id="realistic-distortion-2"><a href="#realistic-distortion-2" class="headerlink" title="realistic distortion 2"></a>realistic distortion 2</h3><p>aerial  image dataset DOTA</p>
<p>GSD (ground sample distances), </p>
<p>62 LR images GSD在[55cm, 65cm]之间， HR image的GSD为30cm</p>
<p>超参：$\lambda_{cyc}=1,\lambda_{\bar{idt}}=10,\lambda_{geo}=100,\gamma=0.1$ , 2倍SR</p>
<p>在这种数据集里，物体的像素点很少，所以对identity loss和geometric loss用了更大的权重。在训练初期，逐步提高geometric loss的权重。</p>
<p><img src="/2021/04/09/Unpaired%20Image%20Super-Resolution%20using%20Pseudo-Supervision/image-20210409162312918.png" alt></p>
<p>只提供视觉上的比较，因为没有GT。</p>
<p>先用RL-restore（强化学习blind去噪修复）在input的LR image上去噪。但是他的输出over-smoothed. 即使再用SOTA的blind SR方法ZSSR超分辨，artifacts也不能被完全移除。</p>
<p>geometric loss的作用：</p>
<p><img src="/2021/04/09/Unpaired%20Image%20Super-Resolution%20using%20Pseudo-Supervision/image-20210409162239831.png" alt></p>
<h3 id="AIM-2019-real-world-SR-challenge"><a href="#AIM-2019-real-world-SR-challenge" class="headerlink" title="AIM 2019 real world SR challenge"></a>AIM 2019 real world SR challenge</h3><p>没有HR-LR pair,测试时有官方的脚步来计算PSNR/SSIM。 $\lambda_{cyc}=1,\lambda_{\bar{idt}}=5,\lambda_{geo}=1,\gamma=0.1$</p>
<p>​        LPIPS: 视觉指标，越低越好。</p>
<p><img src="/2021/04/09/Unpaired%20Image%20Super-Resolution%20using%20Pseudo-Supervision/image-20210409162216094.png" alt></p>

          
            <div class='article_footer'>
              
                
  
    
    



  

  
    
    



  

  
    
    

<section class="widget copyright  desktop mobile">
  <div class='content'>
    
      
    
  </div>
</section>

  


              
            </div>
          
        </div>
        
          


  <section class='meta' id="footer-meta">
    <div class='new-meta-box'>
      
        
          <div class="new-meta-item date" itemprop="dateUpdated" datetime="2021-04-09T16:26:08+08:00">
  <a class='notlink'>
    <i class="fas fa-edit fa-fw" aria-hidden="true"></i>
    <p>更新于：Apr 9, 2021</p>
  </a>
</div>

        
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/super-resolution/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>super-resolution</p></a></div> <div class="new-meta-item meta-tags"><a class="tag" href="/tags/pseudo-supervision/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>pseudo-supervision</p></a></div> <div class="new-meta-item meta-tags"><a class="tag" href="/tags/unpaired/" rel="nofollow"><i class="fas fa-hashtag fa-fw" aria-hidden="true"></i><p>unpaired</p></a></div>


        
      
        
          

        
      
        
          

        
      
    </div>
  </section>


        
        
          <div class="prev-next">
            
              <a class='prev' href='/2021/04/10/%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%87_Toward%20Convolutional%20Blind%20Denoising%20of%20Real%20Photographs/'>
                <p class='title'><i class="fas fa-chevron-left" aria-hidden="true"></i>阅读论文-Toward Convolutional Blind Denoising of Real Photographs</p>
                <p class='content'>
出处：CVPR2019

paper  code  
motivation尽管之前一些基于CNN的算法在图像的加性高斯白噪声去除上取得了很好的效果，但这些方法往往是在过拟合AWGN，而在真实噪...</p>
              </a>
            
            
              <a class='next' href='/2021/04/09/Dual%20super-resolution%20learning%20for%20semantic%20segmentation/'>
                <p class='title'>阅读论文-Dual super-resolution learning for semantic segmentation<i class="fas fa-chevron-right" aria-hidden="true"></i></p>
                <p class='content'>
出处：CVPR2020 (oral)

paper  code  unofficial-code
motivation在不增加计算开销的前提下提高语义分割的性能，而语义分割依赖于HR feat...</p>
              </a>
            
          </div>
        
      </section>
    </article>
  

  
    <!-- 显示推荐文章和评论 -->



  


  




<!-- 根据页面mathjax变量决定是否加载MathJax数学公式js -->

  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.0/es5/tex-mml-chtml.js"></script>
<!-- MathJax配置，可通过单美元符号书写行内公式等 -->

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.0/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>




  <script>
    window.subData = {
      title: '阅读论文-Unpaired Image Super-Resolution using Pseudo-Supervision',
      tools: true
    }
  </script>


</div>
<aside class='l_side'>
  
  

  
    
    


  <section class="widget toc-wrapper shadow desktop mobile">
    
  <header>
    
      <i class="fas fa-list fa-fw" aria-hidden="true"></i><span class='name'>本文目录</span>
    
  </header>


    <div class='content'>
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#motivation"><span class="toc-text">motivation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#contribution"><span class="toc-text">contribution</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#related-works"><span class="toc-text">related works</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#method"><span class="toc-text">method</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#loss-function"><span class="toc-text">loss function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#network-architecture"><span class="toc-text">network architecture</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Experiments"><span class="toc-text">Experiments</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#synthetic-distortions"><span class="toc-text">synthetic distortions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#realistic-distortion-1"><span class="toc-text">realistic distortion 1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#realistic-distortion-2"><span class="toc-text">realistic distortion 2</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AIM-2019-real-world-SR-challenge"><span class="toc-text">AIM 2019 real world SR challenge</span></a></li></ol></li></ol>
    </div>
  </section>


  


</aside>


  
  <footer class="clearfix">
    <br><br>
    
      
        <div class="aplayer-container">
          


        </div>
      
    
      
        <br>
        <div class="social-wrapper">
          
            
              <a href="/atom.xml"
                class="social fas fa-rss flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
              </a>
            
          
            
          
            
              <a href="https://github.com/Shiyuuuu"
                class="social fab fa-github flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer">
              </a>
            
          
            
          
        </div>
      
    
      
        <div><p>Blog content follows the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener">Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License</a></p>
</div>
      
    
      
        Use
        <a href="https://volantis.js.org/" target="_blank" class="codename">Volantis</a>
        as theme, total visits
          <span id="busuanzi_value_site_pv"><i class="fas fa-circle-notch fa-spin fa-fw" aria-hidden="true"></i></span>
          times
        
      
    
      
        <div class='copyright'>
        <p><a href="https://xaoxuu.com" target="_blank" rel="noopener">Copyright © 2017-2020 Mr. X</a></p>

        </div>
      
    
  </footer>

<script>setLoadingBarProgress(80);</script>


      <script>setLoadingBarProgress(60);</script>
    </div>
    <a class="s-top fas fa-arrow-up fa-fw" href='javascript:void(0)'></a>
  </div>
  
<script src="https://cdn.jsdelivr.net/npm/jquery@3.4/dist/jquery.min.js"></script>


  <script>
    
    var SEARCH_SERVICE = "hexo" || "hexo";
    var ROOT = "/" || "/";
    if (!ROOT.endsWith('/')) ROOT += '/';
  </script>


  <script async src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2/js/instant_page.js" type="module" defer integrity="sha384-OeDn4XE77tdHo8pGtE1apMPmAipjoxUQ++eeJa6EtJCfHlvijigWiJpD7VDPWXV1"></script>


  <script src="https://cdn.jsdelivr.net/npm/scrollreveal@4.0.6/dist/scrollreveal.min.js"></script>
  <script type="text/javascript">
    $(function() {
      ScrollReveal().reveal('.l_main .reveal', {
        distance: '8px',
        duration: '800',
        interval: '100',
        scale: '1'
      });
    });
  </script>


  
<script src="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.js"></script>

  <script type="text/javascript">
    $(function() {
      Waves.attach('.flat-btn', ['waves-button']);
      Waves.attach('.float-btn', ['waves-button', 'waves-float']);
      Waves.attach('.float-btn-light', ['waves-button', 'waves-float', 'waves-light']);
      Waves.attach('.flat-box', ['waves-block']);
      Waves.attach('.float-box', ['waves-block', 'waves-float']);
      Waves.attach('.waves-image');
      Waves.init();
    });
  </script>


  <script defer src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-busuanzi@2.3/js/busuanzi.pure.mini.js"></script>



  
  
  
    
<script src="https://cdn.jsdelivr.net/npm/jquery-backstretch@2.1.18/jquery.backstretch.min.js"></script>

    <script type="text/javascript">
      $(function(){
        var imgs=["https://cdn.jsdelivr.net/gh/Shiyuuuu/CDN/Sakura-bloom-pink-flowers-twigs-spring_3840x2160.jpg"];
        if ('true' == 'true') {
          function shuffle(arr){
            /*From countercurrent-time*/
            var n = arr.length;
            while(n--) {
              var index = Math.floor(Math.random() * n);
              var temp = arr[index];
              arr[index] = arr[n];
              arr[n] = temp;
            }
          }
          shuffle(imgs);
        }
        if ('.cover') {
          $('.cover').backstretch(
            imgs,
          {
            duration: "20000",
            fade: "1500"
          });
        } else {
          $.backstretch(
            imgs,
          {
            duration: "20000",
            fade: "1500"
          });
        }
      });
    </script>
  















  
<script src="/js/app.js"></script>



  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2.6.5/js/search.js"></script>



  
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/cdn-volantis@2/js/comment_typing.js"></script>






<!-- 复制 -->

  <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="fas fa-copy"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('fa-copy');
        $icon.addClass('fa-check-circle');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('fa-check-circle');
          $icon.addClass('fa-copy');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('fa-copy');
        $icon.addClass('fa-times-circle');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('fa-times-circle');
          $icon.addClass('fa-copy');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>




<!-- fancybox -->
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>
<script>
  function pjax_fancybox() {
    $(".article-entry").find("img").not('.inline').not('a img').each(function () { //渲染 fancybox
      var element = document.createElement("a"); // a 标签
      $(element).attr("pjax-fancybox", "");  // 过滤 pjax
      $(element).attr("href", $(this).attr("src"));
      if ($(this).attr("data-original")) {
        $(element).attr("href", $(this).attr("data-original"));
      }
      $(element).attr("data-fancybox", "images");
      var caption = "";   // 描述信息
      if ($(this).attr('alt')) {  // 标准 markdown 描述信息
        $(element).attr('data-caption', $(this).attr('alt'));
        caption = $(this).attr('alt');
      }
      var div = document.createElement("div");
      $(div).addClass("fancybox");
      $(this).wrap(div); // 最外层套 div ，其实主要作用还是 class 样式
      var span = document.createElement("span");
      $(span).addClass("image-caption");
      $(span).text(caption); // 加描述
      $(this).after(span);  // 再套一层描述
      $(this).wrap(element);  // 最后套 a 标签
    })
    $(".article-entry").find("img").fancybox({
      selector: '[data-fancybox="images"]',
      hash: false,
      loop: false,
      closeClick: true,
      helpers: {
        overlay: {closeClick: true}
      },
      buttons: [
        "zoom",
        "close"
      ]
    });
  };
  $(function () {
    pjax_fancybox();
  });
</script>




  <script>setLoadingBarProgress(100);</script>
</body>
</html>
