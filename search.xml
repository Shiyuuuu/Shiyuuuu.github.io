<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>ubuntu 踩坑记录</title>
    <url>/2021/03/26/ubuntu%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<h1 id="ubuntu-踩坑记录"><a href="#ubuntu-踩坑记录" class="headerlink" title="ubuntu 踩坑记录"></a>ubuntu 踩坑记录</h1><h2 id="显卡驱动重装"><a href="#显卡驱动重装" class="headerlink" title="显卡驱动重装"></a>显卡驱动重装</h2><p>某次装好后，遇到bug：</p>
<blockquote>
<p>Can’t run remote python interpreter: OCI runtime create failed: container_linux.go:367: starting container process caused: process_linux.go:495: container init caused: Running hook #1:: error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: initialization error: driver error: failed to process request: unknown</p>
</blockquote>
<a id="more"></a>
<p>docker 里nvidia-smi不能用了，直接在docker外nvidia-smi也报错：</p>
<blockquote>
<p>NVIDIA-SMI couldn’t find libnvidia-ml.so library in your system. Please make sure that the NVIDIA Display Driver is properly installed and present in your system. Please also try adding directory that contains libnvidia-ml.so to your system PATH.</p>
</blockquote>
<p>估计是什么时候update弄成的。</p>
<p>解决方法：重装显卡驱动</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># BTW this is all in console mode (for me, alt+ctrl+F2)</span></span><br><span class="line"><span class="comment"># login + password as usual</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># removing ALL nvidia software</span></span><br><span class="line">$ sudo apt-get purge nvidia* </span><br><span class="line"></span><br><span class="line"><span class="comment"># Checking what's left:</span></span><br><span class="line">$ dpkg -l | grep nvidia</span><br><span class="line"><span class="comment"># Then I deleted the ones that showed up (mostly libnvidia-* but also xserver-xorg-video-nvidia-xxx`)</span></span><br><span class="line">$ sudo apt-get purge libnvidia* xserver-xorg-video-nvidia-440 </span><br><span class="line">$ sudo apt autoremove <span class="comment"># clean it up</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># now reinstall everything including nvidia-common</span></span><br><span class="line">$ sudo apt-get nvidia-common</span><br><span class="line"></span><br><span class="line"><span class="comment"># find the right driver again</span></span><br><span class="line">$ sudo add-apt-repository ppa:graphics-drivers/ppa</span><br><span class="line">$ sudo apt update</span><br><span class="line">$ ubuntu-drivers devices</span><br><span class="line">$ sudo apt-get install nvidia-driver-460 <span class="comment"># the recommended one by ubuntu-drivers</span></span><br><span class="line">$ update-initramfs -u <span class="comment"># needed to do this so rebooting wouldn't lose configuration I think</span></span><br><span class="line"></span><br><span class="line">$ sudo reboot</span><br></pre></td></tr></table></figure>
<p>然后再重装NVIDIA-docker：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$curl</span> -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -</span><br><span class="line"><span class="variable">$curl</span> -s -L https://nvidia.github.io/nvidia-docker/ubuntu18.04/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list</span><br><span class="line"><span class="variable">$sudo</span> apt-get update</span><br><span class="line"></span><br><span class="line"><span class="variable">$sudo</span> apt-get install nvidia-docker2</span><br><span class="line"><span class="variable">$sudo</span> pkill -SIGHUP dockerd</span><br><span class="line"><span class="variable">$docker</span> run --runtime=nvidia --rm nvidia/cuda nvidia-smi</span><br></pre></td></tr></table></figure>
<p>测试：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo nvidia-docker run --rm nvidia/cuda:10.1-devel nvidia-smi</span><br></pre></td></tr></table></figure>
<p>万幸CUDA, CuDNN都还有。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.cuda.is_available()</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a=torch.randn(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.cuda()</span><br><span class="line">tensor([[<span class="number">-0.4678</span>,  <span class="number">0.1525</span>]], device=<span class="string">'cuda:0'</span>)</span><br></pre></td></tr></table></figure>
<p> 配置默认运行的是nvidia-docker 而不是 docker (<a href="https://zhuanlan.zhihu.com/p/37519492)，在/etc/docker/daemon.json" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/37519492)，在/etc/docker/daemon.json</a> 文件中配置如下内容：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;default-runtime&quot;: &quot;nvidia&quot;,</span><br><span class="line">    &quot;runtimes&quot;: &#123;</span><br><span class="line">        &quot;nvidia&quot;: &#123;</span><br><span class="line">            &quot;path&quot;: &quot;&#x2F;usr&#x2F;bin&#x2F;nvidia-container-runtime&quot;,</span><br><span class="line">            &quot;runtimeArgs&quot;: [],</span><br><span class="line">            &quot;registry-mirrors&quot;: [&quot;https:&#x2F;&#x2F;gemfield.mirror.aliyuncs.com&quot;]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="pycharm里用docker"><a href="#pycharm里用docker" class="headerlink" title="pycharm里用docker"></a>pycharm里用docker</h2><p>python 位置：/home/shiyuuuu/anaconda3/bin/python</p>
<p><img src="/2021/03/26/ubuntu%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/image-20210326170845579.png" alt="image-20210326170845579"></p>
]]></content>
      <categories>
        <category>ubuntu</category>
        <category>bug</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>bug</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>1-两数之和</title>
    <url>/2021/03/26/1_%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C/</url>
    <content><![CDATA[<h1 id="1-两数之和"><a href="#1-两数之和" class="headerlink" title="1. 两数之和"></a>1. 两数之和</h1><p><a href="https://leetcode-cn.com/problems/two-sum" target="_blank" rel="noopener">https://leetcode-cn.com/problems/two-sum</a></p>
<h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><p>给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 的那 两个 整数，并返回它们的数组下标。<br><a id="more"></a><br>你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。<br>你可以按任意顺序返回答案。</p>
<p>示例 1：</p>
<blockquote>
<p>输入：nums = [2,7,11,15], target = 9<br>输出：[0,1]<br>解释：因为 nums[0] + nums[1] == 9 ，返回 [0, 1] 。</p>
</blockquote>
<p>示例 2：</p>
<blockquote>
<p>输入：nums = [3,2,4], target = 6<br>输出：[1,2]</p>
</blockquote>
<p>示例 3</p>
<blockquote>
<p>输入：nums = [3,3], target = 6<br>输出：[0,1]</p>
</blockquote>
<p>提示：</p>
<blockquote>
<p>2 &lt;= nums.length &lt;= 103<br>-109 &lt;= nums[i] &lt;= 109<br>-109 &lt;= target &lt;= 109<br>只会存在一个有效答案</p>
</blockquote>
<h2 id="暴力解答"><a href="#暴力解答" class="headerlink" title="暴力解答"></a>暴力解答</h2><p>我自己的解答：非常暴力检索，第一个:  <code>i</code> 从0到n，第二个: <code>j</code> 从i+1 到n（或者倒序来）。这样复杂度是O(n^2)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">twoSum</span><span class="params">(self, nums: List[int], target: int)</span> -&gt; List[int]:</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>,len(nums)):</span><br><span class="line">                <span class="keyword">if</span> nums[i]+nums[j]==target:</span><br><span class="line">                    <span class="keyword">return</span> [i,j]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">twoSum</span><span class="params">(self, nums: List[int], target: int)</span> -&gt; List[int]:</span></span><br><span class="line">        <span class="comment"># nums_sorted=sorted(nums)</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(len(nums)<span class="number">-1</span>,i,<span class="number">-1</span>):</span><br><span class="line">                <span class="keyword">if</span> nums[i]+nums[j]==target:</span><br><span class="line">                    c=sorted([i,j])</span><br><span class="line">                    <span class="keyword">return</span> c</span><br></pre></td></tr></table></figure>
<h2 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h2><p>哈希表博文：<a href="/2021/03/26/%E5%93%88%E5%B8%8C%E8%A1%A8/" title="哈希表">哈希表</a></p>
<h3 id="思路及算法"><a href="#思路及算法" class="headerlink" title="思路及算法"></a>思路及算法</h3><p>注意到方法一的时间复杂度较高的原因是寻找 target - x 的时间复杂度过高。因此，我们需要一种更优秀的方法，能够快速寻找数组中是否存在目标元素。如果存在，我们需要找出它的索引。</p>
<p>使用哈希表，可以将寻找 target - x 的时间复杂度降低到从 <strong><em>O(N)</em></strong> 降低到 <strong><em>O(1)</em></strong>。</p>
<p>这样我们创建一个哈希表，对于每一个 x，我们首先查询哈希表中是否存在 target - x，然后将 x 插入到哈希表中，即可保证不会让 x 和自己匹配。</p>
<p>先建立一个空字典，查找target-num是不是hashtable的键值，如果是，直接return，如果不是，把这个num-i对以键值对的形式添加入字典。哈希表查找元素的复杂度为<strong><em>O(1)</em></strong></p>
<p>代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> List</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">twoSum</span><span class="params">(self, nums: List[int], target: int)</span> -&gt; List[int]:</span></span><br><span class="line">        hashtable = dict()</span><br><span class="line">        <span class="keyword">for</span> i, num <span class="keyword">in</span> enumerate(nums):</span><br><span class="line">            <span class="keyword">if</span> target - num <span class="keyword">in</span> hashtable:</span><br><span class="line">                <span class="keyword">return</span> [hashtable[target - num], i]</span><br><span class="line">            hashtable[nums[i]] = i</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line">s=Solution()</span><br><span class="line"><span class="comment"># nums=[2,7,11,15]</span></span><br><span class="line"><span class="comment"># target=9</span></span><br><span class="line"><span class="comment"># nums = [3,2,4]</span></span><br><span class="line"><span class="comment"># target = 6</span></span><br><span class="line">nums = [<span class="number">3</span>,<span class="number">3</span>]</span><br><span class="line">target = <span class="number">6</span></span><br><span class="line">a=s.twoSum(nums,target)</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure>
<h3 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p>时间复杂度：O(N)，其中 N是数组中的元素数量。对于每一个元素 x，我们可以 O(1) 地寻找 target - x。</p>
<p>空间复杂度：O(N)，其中 N 是数组中的元素数量。主要为哈希表的开销。</p>
]]></content>
      <categories>
        <category>LeetCode</category>
        <category>algorithm</category>
        <category>easy</category>
        <category>哈希表</category>
      </categories>
      <tags>
        <tag>哈希表</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title>哈希表</title>
    <url>/2021/03/26/%E5%93%88%E5%B8%8C%E8%A1%A8/</url>
    <content><![CDATA[<h1 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h1><p>Hash Table，也叫散列表。<a href="/2021/03/26/1_%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C/" title="力扣-两数之和">力扣-两数之和</a></p>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>哈希表</category>
      </categories>
      <tags>
        <tag>哈希表</tag>
      </tags>
  </entry>
  <entry>
    <title>阅读论文-GLEAN Generative Latent Bank for Large-Factor Image Super-Resolution</title>
    <url>/2021/03/29/%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%87GLEAN/</url>
    <content><![CDATA[<p><img src="/2021/03/29/%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%87GLEAN/image-20210329170458177.png" alt></p>
<a id="more"></a>
<p><a href="https://ckkelvinchan.github.io/projects/GLEAN/" target="_blank" rel="noopener">project</a>  code <a href="https://arxiv.org/pdf/2012.00739.pdf" target="_blank" rel="noopener">paper</a></p>
<p>任务是： 大尺度超分辨率（8$\times$ 到 64$\times$），most details and textures are lost during downsampling.</p>
<h2 id="motivation"><a href="#motivation" class="headerlink" title="motivation"></a>motivation</h2><ul>
<li>已有的SR方法：<ul>
<li>solely rely on $L_2$ loss: 视觉质量不好 (over-smoothing artifacts)。</li>
<li>adverssrial loss [ESRGAN]: Generator既要捕获图像characteristics又要保真（maintaining the fidelity to the GT）, 限制了其近似自然图像的能力，产生artifacts</li>
<li>GAN inversion methods [PULSE]：反转pre-trained GAN的生成过程：把image mapping回latent space；再由latent space中optimal vector重建图像。<strong>只靠低维隐向量不足以指导重建的过程</strong>，使得产生的结果low fidelity. 需要image-specific, iterative的优化.</li>
</ul>
</li>
<li>利用pre-trained GAN作为latent bank， 充分利用pre-trained GAN中封装的丰富且多样的先验。换用不同的bank可以不同类的图像：cat，building，human face，car. 利用字典学习的方式，测试阶段，只需要一次前传即可得到恢复后的图像。</li>
<li>GLEAN 的整体结构：encoder-bank-decoder</li>
</ul>
<h2 id="related-work"><a href="#related-work" class="headerlink" title="related work"></a>related work</h2><h3 id="large-factor-SR"><a href="#large-factor-SR" class="headerlink" title="large-factor SR"></a>large-factor SR</h3><ol>
<li>fully probabilistic pixel recursive network for upsampling extremely coarse images with resolution 8×8. (Ryan Dahl, Mohammad Norouzi, and Jonathon Shlens. Pixel recursive super resolution. In ICCV, 2017.)</li>
<li>RFB-ESRGAN：adopts multi-scale receptive fields blocks for 16× SR. (Taizhang Shang, Qiuju Dai, Shengchen Zhu, Tong Yang, and Yandong Guo. Perceptual extreme super resolution network with receptive field block. In CVPRW, 2020.)</li>
<li>VarSR: 8× SR by matching the latent distributions of LR and HR images to recover the missing details. (Sangeek Hyun and Jae-Pil Heo. VarSR: Variational super-resolution network for very low resolution images. In ECCV, 2020.)</li>
<li>perform 16× reference-based SR on paintings with a non-local matching module and a wavelet texture loss. (Yulun Zhang, Zhifei Zhang, Stephen DiVerdi, Zhaowen Wang, Jose Echevarria, and Yun Fu. Texture hallucination for large-scale painting super-resolution. In ECCV, 2020.)</li>
</ol>
<h3 id="GAN-inversion"><a href="#GAN-inversion" class="headerlink" title="GAN inversion"></a>GAN inversion</h3><ol>
<li><p>David Bau, Hendrik Strobelt, William Peebles, Bolei Zhou, Jun-Yan Zhu, Antonio Torralba, et al. Semantic photo manipulation with a generative image prior. TOG, 2020.</p>
</li>
<li><p>Jinjin Gu, Yujun Shen, and Bolei Zhou. Image processing using multi-code GAN prior. In CVPR, 2020.</p>
</li>
<li><p>Sachit Menon, Alexandru Damian, Shijia Hu, Nikhil Ravi, and Cynthia Rudin. <strong>PULSE</strong>: Self-supervised photo upsampling via latent space exploration of generative models. In CVPR, 2020.</p>
<p> 通过pixel-wise约束，迭代优化styleGAN的隐变量。</p>
</li>
<li><p>Xingang Pan, Xiaohang Zhan, Bo Dai, Dahua Lin, Chen Change Loy, and Ping Luo. Exploiting deep generative prior for versatile image restoration and manipulation. In ECCV, 2020.</p>
<p> finetune generator和latent code来缩小训练集和测试集分布的gap.</p>
</li>
</ol>
<p>降质图像$x$，latent space：$\mathcal{Z}$：</p>
<script type="math/tex; mode=display">
z^*=argmin_{z \in \mathcal{Z}}\mathcal{L}(G(z), x)</script><p><strong><em>缺点：</em></strong></p>
<p>低维的隐向量不能保持图像的spatial information.</p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>passing both the latent vectors and multi-resolution convolutional features from the encoder.</p>
<p>multi-resolution cues need to be passed from the bank to the decoder.</p>
<p><img src="/2021/03/29/%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%87GLEAN/image-20210329194816287.png" alt></p>
<ul>
<li>整个结构为encoder-bank-decoder</li>
<li>encoder：$E_0$为RRDB-Net，$E_i, i \in\{1,…,N\}$代表堆叠一个stride=2的conv和一个stride=1的conv. 最后由FC层得到$C$, $C$表示隐向量，提供high-level信息。为了更好的指导结构重建，将多分辨率的特征和隐向量都送入bank.</li>
<li>Generative latent bank: 用pre-trained的Generator, styleGAN，提供纹理和细节生成的先验。<ul>
<li>对generator的每个block输入不同的隐向量$C_i$, $i \in \{0,…,k-1\}$</li>
<li>$\{g_i\}$代表每个block输出的feature, 它是由$C_i, g_{i-1}, f_{N-i}$由augmented style block得到。</li>
<li>不直接输出结果，而是将特征$\{g_i\}$输入到decoder</li>
<li>优势：像reference-based SR，HR reference image作为显式图像字典。性能很受 输入和reference相似度的影响。GLEAN用GAN-based的字典，不依赖于任何具体的图像，它获取的是图像的分布。而且没有global matching和reference images selection， 计算简便。</li>
</ul>
</li>
<li>decoder：progressive地聚合来自encoder和latent bank的特征。每个conv后跟着pixel-shuffle层。由于有encoder和decoder之间的skip-connection，encoder捕获的信息可以被强化，bank专注于纹理和细节的生成。</li>
<li>训练：$\mathcal{l_2}$ loss, perceptual loss, adversarial loss. 训练时fix住latent bank，实验发现，finetune latent bank没有性能提升，而且可能使latent bank偏向训练集的分布。</li>
</ul>
<h2 id="主要结果"><a href="#主要结果" class="headerlink" title="主要结果"></a>主要结果</h2><p><img src="/2021/03/29/%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%87GLEAN/image-20210329171413782.png" alt></p>
<p><img src="/2021/03/29/%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%87GLEAN/image-20210329203432053.png" alt></p>
<p><img src="/2021/03/29/%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%87GLEAN/image-20210329203534511.png" alt></p>
<h3 id="image-retouching"><a href="#image-retouching" class="headerlink" title="image retouching"></a>image retouching</h3><p><img src="/2021/03/29/%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%87GLEAN/image-20210329203631010.png" alt></p>
<h2 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h2><p>[ESRGAN]: Xintao Wang, Ke Yu, Shixiang Wu, Jinjin Gu, Yihao Liu, Chao Dong, Chen Change Loy, Yu Qiao, and Xiaoou Tang. ESRGAN: Enhanced super-resolution generative adversarial networks. In ECCVW, 2018. </p>
<p>[PULSE]: Sachit Menon, Alexandru Damian, Shijia Hu, Nikhil Ravi, and Cynthia Rudin. PULSE: Self-supervised photo upsampling via latent space exploration of generative models. In CVPR, 2020.</p>
<h3 id="reference-based-SR"><a href="#reference-based-SR" class="headerlink" title="reference-based SR"></a>reference-based SR</h3><ol>
<li>Xiaoming Li, Chaofeng Chen, Shangchen Zhou, Xianhui Lin, Wangmeng Zuo, and Lei Zhang. Blind face restoration via deep multi-scale component dictionaries. In ECCV, 2020.</li>
<li>Xiaoming Li, Wenyu Li, Dongwei Ren, Hongzhi Zhang, Meng Wang, and Wangmeng Zuo. Enhanced blind face restoration with multi-exemplar images and adaptive spatial feature fusion. In CVPR, 2020.</li>
<li>Xu Yan, Weibing Zhao, Kun Yuan, Ruimao Zhang, Zhen Li, and Shuguang Cui. Towards content-independent multi-reference super-resolution: Adaptive pattern matching and feature aggregation. In ECCV, 2020.</li>
<li>Yang Zhang, Ivor W Tsang, Yawei Luo, Changhui Hu, Xiaobo Lu, and Xin Yu. Copy and Paste GAN: Face hallucination from shaded thumbnails. In CVPR, 2020.</li>
<li>Zhifei Zhang, Zhaowen Wang, Zhe Lin, and Hairong Qi. Image super-resolution by neural texture transfer. In CVPR, 2019.</li>
</ol>
]]></content>
      <categories>
        <category>Paper reading</category>
        <category>super-resolution</category>
      </categories>
      <tags>
        <tag>Super-resolution</tag>
        <tag>GAN</tag>
        <tag>highly ill-posed</tag>
      </tags>
  </entry>
</search>
